{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch教程.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3TTxatfK9LcL",
        "th-F_M_sDlt9",
        "1msmpQyuDtCR",
        "Xmg7qTOmFjiB",
        "W_gD27dGq3eB",
        "2-iJJYkJDebi",
        "bzAQUxOiGkrY",
        "3I7cZ4DxJCmT",
        "H3HHO0AT3JSp",
        "cnltjumt6-LY",
        "9zhlW-0QNjXW",
        "EFfuUdo-QYee",
        "YgrC-dU3S6vn",
        "LC0IOsWALphJ",
        "xjmsGXdjBloy",
        "AKKaP7t-HUvP",
        "Kgd4cjtSKJr6",
        "t44SQs8BK1xs",
        "DJcd_Te5UtQj",
        "_KxGMaudf6pO",
        "k-wYiLPourjR",
        "UWUsDADhvL2I",
        "Osp9ksxjw-G7",
        "hPk3G7tzxn69"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kolentokk/test/blob/master/PyTorch%E6%95%99%E7%A8%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWmhnjgpOx2I"
      },
      "source": [
        "# Tensor基本操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjR1BmmWO_Id"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UId1VNTAxauk",
        "outputId": "28ded9be-7bc8-49aa-a4ed-f94acf7e396a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.Tensor(5, 3)  # 构造一个未初始化的5*3的矩阵\n",
        "print(x)\n",
        "x = torch.rand(5, 3)  # 构造一个随机初始化的矩阵\n",
        "print(x)\n",
        "x.size()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.1707e-18, 7.0952e+22, 1.7748e+28],\n",
            "        [1.8176e+31, 7.2708e+31, 5.0778e+31],\n",
            "        [3.2608e-12, 1.7728e+28, 7.0367e+22],\n",
            "        [2.1715e-18, 2.6226e-09, 2.6587e+23],\n",
            "        [5.3242e+22, 8.3092e+20, 1.9971e+20]])\n",
            "tensor([[0.6438, 0.5254, 0.8015],\n",
            "        [0.8777, 0.5450, 0.0079],\n",
            "        [0.5094, 0.6611, 0.3465],\n",
            "        [0.2991, 0.5888, 0.9335],\n",
            "        [0.9578, 0.7809, 0.4834]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVBb1UPcxfYi",
        "outputId": "36ccfef0-1ba8-411c-9234-3b29c3f6ac3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.Size 事实上是一个tuple, 所以其支持相关的操作*\n",
        "y = torch.rand(5, 3)\n",
        "x + y # 语法一\n",
        "torch.add(x, y) # 语法二"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9815, 1.2067, 1.3755],\n",
              "        [0.6702, 0.5304, 0.9676],\n",
              "        [0.7938, 0.7058, 0.8588],\n",
              "        [1.5058, 0.9331, 1.7468],\n",
              "        [1.4405, 0.6854, 0.6840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBemHXdTyZgi",
        "outputId": "8df2bae8-0226-43df-96f5-172114ab569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# 另外输出tensor也有两种写法\n",
        "result = torch.Tensor(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "y.add_(x) # 特别注明：任何可以改变tensor内容的操作都会在方法名后加一个下划线'_'，例如：x.copy_(y), x.t_(), 这俩都会改变x的值"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9815, 1.2067, 1.3755],\n",
              "        [0.6702, 0.5304, 0.9676],\n",
              "        [0.7938, 0.7058, 0.8588],\n",
              "        [1.5058, 0.9331, 1.7468],\n",
              "        [1.4405, 0.6854, 0.6840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXUw5uOHysOR",
        "outputId": "ace4ddd3-151e-4211-a52f-01e89ee7c155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 此处演示tensor和numpy数据结构的相互转换\n",
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "# 此处演示当修改numpy数组之后,与之相关联的tensor也会相应的被修改\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtBIC8RZ0EOJ",
        "outputId": "bbf25441-faed-4d05-bcd1-97f17f60a391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 将numpy的Array转换为torch的Tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xXGLum0JjL"
      },
      "source": [
        "# 另外除了CharTensor之外，所有的tensor都可以在CPU运算和GPU预算之间相互转换\n",
        "# 使用CUDA函数来将Tensor移动到GPU上\n",
        "# 当CUDA可用时会进行GPU的运算\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp1gdTns2fhY"
      },
      "source": [
        "autograd.Variable 这是这个包中最核心的类。 它包装了一个Tensor，并且几乎支持所有的定义在其上的操作。一旦完成了你的运算，你可以调用 .backward()来自动计算出所有的梯度。\n",
        "可以通过属性 .data 来访问原始的tensor，而关于这一Variable的梯度则集中于 .grad 属性中。  \n",
        "![替代文字](https://pic4.zhimg.com/80/v2-08e0530dfd6879ff2bee56cfc5cc5073_hd.jpg)\n",
        "\n",
        "在自动求导中非常重要的类 Function\n",
        "Variable 和 Function 二者相互联系并且构建了一个描述整个运算过程的无环图。每个Variable拥有一个 .creator 属性，其引用了一个创建Variable的 Function。(除了用户创建的Variable其 creator 部分是 None)。\n",
        "\n",
        "如果你想要进行求导计算，你可以在Variable上调用.backward()。 如果Variable是一个标量（例如它包含一个单元素数据），你无需对backward()指定任何参数，然而如果它有更多的元素，你需要指定一个和tensor的形状想匹配的grad_output参数\n",
        "\n",
        "更多关于Variable 和 Function的文档:https://link.zhihu.com/?target=http%3A//pytorch.org/docs/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkkies3H0VsZ",
        "outputId": "2b8edca0-25bc-4646-9d7d-4200f3f63a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "del x\n",
        "#x = Variable(torch.ones(2, 2), requires_grad = True)\n",
        "x = torch.ones((2, 2), requires_grad = True)\n",
        "\n",
        "y = x + 2\n",
        "#y.creator  # 错误\n",
        "y.grad\n",
        "# y 是作为一个操作的结果创建的因此y有一个creator ?????????????????\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "# 现在我们来使用反向传播\n",
        "optimizer = optim.SGD(lr=0.01)\n",
        "optimizer.zero_grad()\n",
        "out.backward()\n",
        "\n",
        "# out.backward()和操作out.backward(torch.Tensor([1.0]))是等价的\n",
        "# 在此处输出 d(out)/dx\n",
        "x.grad"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-1f1972d8ea60>:9: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  y.grad\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1f1972d8ea60>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 现在我们来使用反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SGD.__init__() missing 1 required positional argument: 'params'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6prHX_dA74j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZeYJc268o4",
        "outputId": "8468dbd1-d05e-4982-a7a1-4da14bd30fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(3)\n",
        "x = Variable(x, requires_grad = True)  # 用上一个随机初始化的tensor初始化变量x?????????????????????????\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "x.grad"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TTxatfK9LcL"
      },
      "source": [
        "# Part-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg5GgexZ9FUA",
        "outputId": "0b934b91-94a7-479f-a6e3-7b7a158b6404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.randn((3,3), requires_grad = True)\n",
        "\n",
        "w1 = torch.randn((3,3), requires_grad = True)\n",
        "w2 = torch.randn((3,3), requires_grad = True)\n",
        "w3 = torch.randn((3,3), requires_grad = True)\n",
        "w4 = torch.randn((3,3), requires_grad = True)\n",
        "\n",
        "b = w1*a\n",
        "c = w2*a\n",
        "\n",
        "d = w3*b + w4*c\n",
        "\n",
        "L = 10 - d\n",
        "\n",
        "print(\"The grad fn for a is\", a.grad_fn)\n",
        "print(\"The grad fn for d is\", d.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The grad fn for a is None\n",
            "The grad fn for d is <AddBackward0 object at 0x7fce077bc6a0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#冻结某一层\n",
        "# 定义一个简单的模型\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# 冻结某一层的参数\n",
        "for param in model.conv1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 检查参数是否被冻结\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.requires_grad)"
      ],
      "metadata": {
        "id": "Npurw6HBfstw",
        "outputId": "95ccf1a8-370a-4126-949c-4226edff19e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight False\n",
            "conv1.bias False\n",
            "conv2.weight True\n",
            "conv2.bias True\n",
            "fc.weight True\n",
            "fc.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6OwT47XBg-v"
      },
      "source": [
        "<font face=STCAIYUN color=red size=4>注意：</font>当必须冻结某些图层并在训练时阻止他们更新参数时，可以简单地将requires_grad设置为False，这些Tensors不会参与计算图。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKDwg-fkCZWW"
      },
      "source": [
        "当执行inference code时，并不计算梯度，因此不需要存储这些值。事实上，在推理过程中不需要创建任何图形，因为它将导致无用的内存消耗  \n",
        "PyTorch提供了环境管理器：torch.no_grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJavr9vK9FRa"
      },
      "source": [
        "with torch.no_grad:\n",
        "\tinference code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th-F_M_sDlt9"
      },
      "source": [
        "# Part-2  构建一个神经网络\n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>**1. </font>  <font face=楷体>  如何使用nn.Module类构建神经网络  \n",
        "<font face=STCAIYUN color=skyblue size=4>**2.</font>   如何使用Dataset和Dataloader类使用数据扩充来构建自定义数据输入管道。  \n",
        "<font face=STCAIYUN color=skyblue size=4>**3.  </font> 如何使用不同的学习率计划配置您的学习率  \n",
        "<font face=STCAIYUN color=skyblue size=4>**4. </font> 训练Resnet基础图像分类器来对来自CIFAR-10数据集的图像进行分类。</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1msmpQyuDtCR"
      },
      "source": [
        "## 构造简单的神经网络  \n",
        "![网络图](https://blog.paperspace.com/content/images/2019/06/network.png   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmg7qTOmFjiB"
      },
      "source": [
        "### 预热\n",
        "<font face=楷体 color=skyblue  size=4>torch.nn  模块</font><font face=楷体 >是PyTorch设计神经网络的基石，通过实例化torch.nn.Module对象来实现诸如完全连接层、卷积层、池化层、激活函数及整个神经网络的层</font>  \n",
        "<font face=楷体 color=skyblue  size=4>nn.Module类需要重写（override）两个方法：</font>\n",
        "\n",
        "\n",
        "*   <font face=楷体>__init__方法：创建nn.Module实例时自动调用该方法，在该方法下定义网络层的各种参数，例如：filters，卷积内核尺寸，dropout层的dropout probability等\n",
        "*  forward方法：定义输出的计算方式。不需要显式调用，通过调用nn.Module实例（input作参数）就可以自动调用并运行该方法</font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjbcUOtv9FOy",
        "outputId": "5d07a76d-b934-4a02-dac3-9e2c373ce149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import torchvision\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "class MyLayer(nn.Module):\n",
        "    def __init__(self, param):\n",
        "        super().__init__()\n",
        "        self.param = param\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.param\n",
        "\n",
        "myLayerObject = MyLayer(5)\n",
        "output = myLayerObject(torch.Tensor([5, 4, 3]) )    # 非显式调用forward方法\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([25., 20., 15.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qbid2JwqPT4"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>nn.Sequential类：</font><font face=楷体>可以按特定顺序传递对象列表，并按顺序返回nn.Module对象</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaagmCn49FMM"
      },
      "source": [
        "combinedNetwork = nn.Sequential(MyLayer(5), MyLayer(10))\n",
        "\n",
        "output = combinedNetwork([3,4])\n",
        "\n",
        "#equivalent to..\n",
        "# out = MyLayer(5)([3,4])\n",
        "# out = MyLayer(10)(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_gD27dGq3eB"
      },
      "source": [
        "### 开始构建网络    \n",
        "<font face=楷体 color=skyblue  size=4>搭建残差模块（ResNet Block）</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/06/resblk.png)\n",
        "<font face=楷体 color=yellow  size=4>疑问：</font>  \n",
        "~~~\n",
        "line23: self.shortcut = nn.Sequential()\n",
        "line28: kernel_size=(1, 1)  #1x1的卷积核？？\n",
        "line34: out = nn.ReLU()(self.bn1(self.conv1(x))) # 直接输入参数？？\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF-qTTBP9FJK"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # Conv Layer 1\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels, out_channels=out_channels,\n",
        "            kernel_size=(3, 3), stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Conv Layer 2\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=out_channels, out_channels=out_channels,\n",
        "            kernel_size=(3, 3), stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection to downsample residual\n",
        "        # In case the output dimensions of the residual block is not the same\n",
        "        # as it's input, have a convolutional layer downsample the layer\n",
        "        # being bought forward by approporate striding and filters\n",
        "        self.shortcut = nn.Sequential()  # 对应上图左边情况，直接连接\n",
        "        if stride != 1 or in_channels != out_channels:  # 对应上图右边stride不等于1或input和output不一样时，需要对x降采样后连接\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels, out_channels=out_channels,\n",
        "                    kernel_size=(1, 1), stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = nn.ReLU()(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olj2tczOv4qR"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>搭建残差网络（ResNet）</font>  \n",
        "<font face=楷体 color=yellow  size=4>疑问</font>  \n",
        "~~~\n",
        "line35: out = out.view(out.size(0), -1)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_9C4cFW9FF9"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        # Initial input conv\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=(3, 3),\n",
        "            stride=1, padding=1, bias=False\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Create blocks\n",
        "        self.block1 = self._create_block(64, 64, stride=1)\n",
        "        self.block2 = self._create_block(64, 128, stride=2)\n",
        "        self.block3 = self._create_block(128, 256, stride=2)\n",
        "        self.block4 = self._create_block(256, 512, stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    # A block is just two residual blocks for ResNet18\n",
        "    def _create_block(self, in_channels, out_channels, stride):\n",
        "        return nn.Sequential(\n",
        "            ResidualBlock(in_channels, out_channels, stride),\n",
        "            ResidualBlock(out_channels, out_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\t# Output of one layer becomes input to the next\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        out = nn.AvgPool2d(4)(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH2wrgnRv-6o"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>输入格式：</font><font face=楷体 >图像的输入格式是[B C H W]  \n",
        "B批量大小、C通道、H高度、W宽度</font>  \n",
        "<font face=楷体 color=skyblue  size=4>加载数据：</font><font face=楷体 >这里用到torch.utils.data.Dataset和torch.utils.data.Dataloader  \n",
        "    将CIFAR-10数据集下载到当前目录"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1TsNo_TukFK",
        "outputId": "2a77ff99-1782-46a8-c9a4-fe683efa78a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "!wget http://pjreddie.com/media/files/cifar.tgz\n",
        "!tar xzf cifar.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-18 07:12:36--  http://pjreddie.com/media/files/cifar.tgz\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/cifar.tgz [following]\n",
            "--2019-09-18 07:12:36--  https://pjreddie.com/media/files/cifar.tgz\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168584360 (161M) [application/octet-stream]\n",
            "Saving to: ‘cifar.tgz’\n",
            "\n",
            "cifar.tgz           100%[===================>] 160.77M  9.29MB/s    in 14s     \n",
            "\n",
            "2019-09-18 07:12:51 (11.8 MB/s) - ‘cifar.tgz’ saved [168584360/168584360]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaZnxqM-1zFK"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>读取CIFAR数据集中存在的类的标签</font>  \n",
        "<font face=楷体 color=yellow  size=4>疑问</font>  \n",
        "~~~\n",
        "line5: label_mapping = dict(zip(labels, list(range(len(labels)))))\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvjHQUUukC8"
      },
      "source": [
        "data_dir = \"cifar/train/\"\n",
        "\n",
        "with open(\"cifar/labels.txt\") as label_file:\n",
        "    labels = label_file.read().split()\n",
        "    label_mapping = dict(zip(labels, list(range(len(labels)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7OmnIqZ2n-Q"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>用PIL读取图像：</font>\n",
        "\n",
        "\n",
        "*   <font face=楷体>随机水平翻转图片的概率为0.5\n",
        "*   使用CIFAR数据集的均值和标准差来标准化图像\n",
        "*   图片格式变换：$W\\times H\\times C\\Longrightarrow C\\times H\\times W$</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UysrgabukAT"
      },
      "source": [
        "def preprocess(image):\n",
        "    image = np.array(image)\n",
        "\n",
        "    if random.random() > 0.5:\n",
        "        image = image[::-1,:,:]\n",
        "\n",
        "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
        "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
        "    image = (image - cifar_mean) / cifar_std\n",
        "\n",
        "    image = image.transpose(2,1,0)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkrqtu9j4Tdy"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>加载数据：</font>  \n",
        "<font face=楷体>torch.utils.data.dataset：是一个加载数据并返回生成器的类，允许将数据增强融合到input Pipeline中</font>    \n",
        "<font face=楷体 color=skyblue>dataset为数据创建对象，需要重载三个方法：  </font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>\n",
        "    <font face=楷体 color=skyblue>__init __方法：</font>\n",
        "    定义与数据集相关的内容：数据位置，各种数据扩充等\n",
        "*  <font face=楷体 color=skyblue> __len __方法：</font>\n",
        "    返回数据的长度\n",
        "*   <font face=楷体 color=skyblue>__getitem __方法：</font>\n",
        "    将索引作为对象的参数，通过给定索引获取数据和标签（对象[索引]）\n",
        "</font>    \n",
        "\n",
        "<font face=楷体 color=yellow  size=4>疑问：</font>    \n",
        "  __getitem __方法  \n",
        "  transforms 数据扩充\n",
        "  ~~~\n",
        "  line32：image = image.astype(np.float32)\n",
        "  ~~~\n",
        "  <font face=楷体 color=green  size=4>**绿色链接：** </font>  \n",
        "   <font face=楷体>\n",
        "  [【1】PyTorch源码解读之torchvision.transforms](https://blog.csdn.net/u014380165/article/details/79167753)\n",
        "     </font>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebfdwmiuj9s"
      },
      "source": [
        "class Cifar10Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, data_size = 0, transforms = None):\n",
        "        files = os.listdir(data_dir)\n",
        "        files = [os.path.join(data_dir,x) for x in files]\n",
        "\n",
        "\n",
        "        if data_size < 0 or data_size > len(files):\n",
        "            assert(\"Data size should be between 0 to number of files in the dataset\")\n",
        "\n",
        "        if data_size == 0:\n",
        "            data_size = len(files)\n",
        "\n",
        "        self.data_size = data_size\n",
        "        self.files = random.sample(files, self.data_size)  # 打乱顺序\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_address = self.files[idx]\n",
        "        image = Image.open(image_address)\n",
        "        image = preprocess(image)\n",
        "        label_name = image_address[:-4].split(\"_\")[-1]\n",
        "        label = label_mapping[label_name]\n",
        "\n",
        "        image = image.astype(np.float32)\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgMOCRTtaJ2M"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>torch.utils.data.Dataloader：</font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>批处理数据\n",
        "*   混排（Shuffling）数据\n",
        "*   多线程一次加载多个数据\n",
        "*   预读，即当GPU处理当前批数据时，Dataloader可以同时将下一批数据加载到内存中。这意味着GPU不必等待，加快训练速度</font>\n",
        "\n",
        "\n",
        "<font face=楷体 color=green  size=4>**绿色链接：**</font>    \n",
        "\n",
        "[【1】PyTorch源码解读之torch.utils.data.DataLoader](https://blog.csdn.net/u014380165/article/details/79058479)  、\n",
        "\n",
        "[【2】SOURCE CODE FOR TORCH.UTILS.DATA.DATALOADER](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gkivYCuj7K"
      },
      "source": [
        "trainset = Cifar10Dataset(data_dir = \"cifar/train/\", transforms=None)\n",
        "# 第一个参数：可迭代Dataset对象；num_workers：线程数\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = Cifar10Dataset(data_dir = \"cifar/test/\", transforms=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uujxT58yuj4m"
      },
      "source": [
        "for data in trainloader:   # or trainset 注意区别\n",
        "\timg, label = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-vZWVdWEM9R"
      },
      "source": [
        "<font face=楷体 color=yellow size=4>\n",
        "DataLoader和Dataset都是返回可迭代对象\n",
        "</font>\n",
        "\n",
        "*  <font face=楷体> __ getitem__方法trainset返回一个numpy数组($C\\times H\\times W$)，Dataloader将图像批量化为Tensor($B\\times C\\times H\\times W$)\n",
        "*   __ getitem__方法输出一个numpy数组，但Dataloader类会自动将其转换为Tensor\n",
        "*   __ getitem__方法返回一个非数字类型的对象，Dataloader该类也将其转换为大小的列表/元组B（在我们的例子中为128）。假设   __getitem__  还返回一个字符串，即标签字符串。如果我们在实例化dataloader时设置batch = 128，那么每次迭代Dataloader都会给我们一个128字符串的元组。\n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd7SZFk1l82E"
      },
      "source": [
        "### 训练和评估  \n",
        "<font face=楷体 color=skyblue size=4>\n",
        "torch.optim模块训练/优化\n",
        "</font>          \n",
        "\n",
        "\n",
        "*   <font face=楷体>不同的优化算法（如：optim.SGD，optim.Adam）\n",
        "*   设置学习率（有optim.lr_scheduler）\n",
        "*   可为不同的参数设置不同的学习率\n",
        "    </font>    \n",
        "    \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>    \n",
        "clf.parameters()\n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接：**</font>    \n",
        "<font face=楷体>\n",
        "[【1】pytorch使用torch.dtype、torch.device和torch.layout管理数据类型属性](https://ptorch.com/news/187.html)  \n",
        "[【2】torch.cuda](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-cuda/)  \n",
        "[【3】torch.optim](https://ptorch.com/docs/1/optim)\n",
        " </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv95B2owuj1r"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     # Check whether a GPU is present.\n",
        "\n",
        "clf = ResNet()\n",
        "clf.to(device)   # Put the network on GPU if present\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # 创建对象\n",
        "optimizer = optim.SGD(clf.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)  # clf.parameters()：神经网络的权重\n",
        "# 衰减因子gamma=0.1；当150 =< epoch < 200 ；lr = gamma * lr\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS1IwZcU3UKr"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>迭代：</font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>先调用scheduler.step()，以确保optimizer使用正确的学习率\n",
        "*    input 和 target $\\Longrightarrow$ GPU 0\n",
        "*   optimizer.zero_grad()：将梯度设置为零，因为Tensor会保留之前的梯度，防止其累积\n",
        "*   torch.no_grad环境管理器：不会为测试部分创建图表</font>    \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>    \n",
        "\n",
        "~~~\n",
        "line24: clf.eval()  \n",
        "~~~\n",
        "<font face=楷体>\n",
        "<font face=楷体 color=green size=4>解答：</font>  \n",
        "    \n",
        "PyTorch中的模型有两个状态eval()和train()，eval()状态下，框架会自动把BN和DropOut固定住，直接用训练好的值  \n",
        "\n",
        "*   训练时是用批处理（min-batch），但测试时往往针对单张图片，即不存在min-batch，由于网络训练完毕后参数都是固定的，每个批次的均值和方差都不变，因此直接结算所有batch的均值和方差，所以Batch Normalization训练和测试时的操作是不同的\n",
        "*   \n",
        "训练时每个隐层的神经元先乘概率P，然后在进行激活；测试时所有的神经元先进行激活，然后每个隐层神经元的输出乘P</font>  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717phvy5ujzE"
      },
      "source": [
        "for epoch in range(10):\n",
        "    losses = []\n",
        "    scheduler.step()\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()                 # Zero the gradients\n",
        "\n",
        "        outputs = clf(inputs)                 # Forward pass\n",
        "        loss = criterion(outputs, targets)    # Compute the Loss\n",
        "        loss.backward()                       # Compute the Gradients\n",
        "\n",
        "        optimizer.step()                      # Updated the weights\n",
        "        losses.append(loss.item())\n",
        "        end = time.time()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Batch Index : %d Loss : %.3f Time : %.3f seconds ' % (batch_idx, np.mean(losses), end - start))\n",
        "\n",
        "            start = time.time()\n",
        "    # Evaluate\n",
        "    clf.eval()  # 将模型设置成evaluation模式，仅当模型中有Dropout和BatchNorm有影响\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = clf(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
        "        print('--------------------------------------------------------------')\n",
        "    clf.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-iJJYkJDebi"
      },
      "source": [
        "# part-3 深入研究PyTorch  \n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>**1. </font>  <font face=楷体>  nn.Module，nn.Functional，nn.Parameter等PyTorch类之间的差别及如何应用  \n",
        "<font face=STCAIYUN color=skyblue size=4>**2.</font>   学习如何使用Dataset及如何自定义训练，如：在不同网络层设置不同的学习率  \n",
        "<font face=STCAIYUN color=skyblue size=4>3.  </font> 初始化权重\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzAQUxOiGkrY"
      },
      "source": [
        "## nn.Module <font face=STCAIYUN color=yellow  size=5>vs</font> nn.Functional</font>   \n",
        "<font face=楷体><font face=楷体 color=skyblue >torch.nn.Module</font>   是PyTorch的基石\n",
        "    \n",
        "<font face=楷体 color=skyblue >使用方式：</font> 先定义一个nn.Module对象，然后调用它的forward方法来运行它，是以一种面向对象的方式。\n",
        "    \n",
        "<font face=楷体 color=skyblue >nn.functional</font>提供一些函数形式的layers/activations，可以直接调用。如：调整图像的tensor shape可以调用torch.nn.functional.interpolate\n",
        "</font>     \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNBHU7gvNAgr",
        "outputId": "34c09df8-4622-4bb1-b2f7-43244b92822b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "inp = torch.randn(1,3,64,64)     # random input image\n",
        "\n",
        "# Same thing using two approaches\n",
        "\n",
        "# torch.nn\n",
        "avg_pool = nn.AvgPool2d(4)     # create an object\n",
        "nn_out = avg_pool(inp)         # invoke the forward method\n",
        "\n",
        "# torch.nn.Functional\n",
        "f_out = F.avg_pool2d(inp, 4)\n",
        "\n",
        "print (torch.equal(nn_out, f_out))        # check whether the same result is produced"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvj6j5gFNMsC"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>了解状态</font>  \n",
        "<font face=楷体>\n",
        "任何层都可以看作是一个函数（如：卷积运算只是一堆乘法和加法运算），但绝不仅仅是一个函数，train()状态时，它还要保存权重（eval()状态时不需要），这些权重在随着训练不断变化 ；实现一个执行卷积运算的函数，还需要定义一个数据结构来保持层的权重与函数本身分开，将此外部数据结构作为函数的输入（或者定义一个类来保存数据结构，并将卷积操作作为成员函数）。  \n",
        "    \n",
        "所以，<font face=楷体 color=skyblue >需要保存、更新权重或定义层其他行为状态更倾向于使用nn.Module对象</font>  ，如：dropout / Batch Norm层（训练和测试时表现不同）\n",
        "    \n",
        "<font face=楷体 color=skyblue >如果不需要任何状态或权重，可以使用nn.functional</font>  ，如：resizing（nn.functional.interpolate），average pooling（nn.functional.AvgPool2d）\n",
        " </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I7cZ4DxJCmT"
      },
      "source": [
        "## nn.Parameter  \n",
        "<font face=楷体>\n",
        "每个nn.Module都有一个parameters()函数，返回训练参数 ，这些参数都是隐式定义的，<font color=yellow>如： </font>\n",
        "\n",
        "将权重和偏差定义为nn.Conv2d层的参数（parameters），\n",
        "nn.Conv2d对象作为net对象的成员，将nn.Conv2d的parameters<font color=yellow>隐式地</font>添加到net的parameters\n",
        "</font>  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To4nGYsBDc-p",
        "outputId": "3844f68d-b014-4e9b-dd45-b8b7dc638278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "class net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)  # return self.conv(x)??\n",
        "\n",
        "myNet = net()\n",
        "\n",
        "# prints the weights and bias of Linear Layer\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.1947,  0.2861,  0.1414,  0.2056, -0.1336, -0.0566, -0.3113, -0.1674,\n",
            "         -0.1483,  0.2683],\n",
            "        [ 0.1862,  0.0979, -0.2313, -0.0359,  0.0168, -0.0731,  0.2569, -0.2579,\n",
            "          0.0550,  0.3066],\n",
            "        [ 0.0140, -0.1697, -0.1616, -0.2769,  0.0872, -0.0484,  0.1002, -0.1437,\n",
            "         -0.0043,  0.0500],\n",
            "        [-0.0172,  0.2170,  0.2823, -0.2452, -0.0664, -0.3094, -0.2311,  0.1677,\n",
            "          0.3013, -0.1784],\n",
            "        [ 0.1703,  0.1094, -0.1093,  0.1969,  0.0225, -0.3154, -0.2837,  0.2004,\n",
            "         -0.2901,  0.1673]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.3019,  0.1918,  0.2855,  0.1144, -0.1353], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf0gUnfOK2Uw"
      },
      "source": [
        "<font face=楷体>\n",
        "<font face=楷体 color=skyblue >nn.Module类所有训练权重都是作为nn.Parameter对象实现的  </font>\n",
        "    \n",
        "如果尝试为nn.Module对象分配一个张量，除非将其定义为nn.Parameter对象，否则它不会显示在对象中  ，这样做是为了便于可能需要缓存不可微分张量的情况，例如，RNN缓存先前的输出。\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm7TaPGMDc74",
        "outputId": "0d54fb19-f8ba-46fd-e448-3ca3fff96284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "class net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5)\n",
        "        self.tens = torch.ones(3,4)                       # This won't show up in a parameter list\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net1()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.1665, -0.2642,  0.0718, -0.2006,  0.0499,  0.0135, -0.0766,  0.1163,\n",
            "          0.0800, -0.0821],\n",
            "        [-0.0387,  0.3112,  0.2356, -0.2702, -0.2696,  0.3058,  0.2460, -0.1485,\n",
            "          0.1384,  0.2377],\n",
            "        [-0.1640,  0.3129,  0.0364, -0.1695,  0.0565, -0.2870,  0.3117,  0.0307,\n",
            "         -0.3157,  0.3142],\n",
            "        [-0.2387,  0.2817, -0.1971,  0.2939, -0.1499,  0.1677,  0.2117,  0.2806,\n",
            "          0.2014, -0.0293],\n",
            "        [-0.2469,  0.2781, -0.0482, -0.2757, -0.2472,  0.2320,  0.1206, -0.1964,\n",
            "          0.2099, -0.1331]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.2638, -0.1977,  0.2212, -0.2858, -0.1917], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5PNwByG3aNa",
        "outputId": "2fbc872d-dfac-4af6-ddc1-11e49022242e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "class net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5)\n",
        "        self.tens = nn.Parameter(torch.ones(3,4))         # This will show up in a parameter list\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net2()\n",
        "print(list(myNet.parameters()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0588,  0.2875, -0.1365,  0.0336,  0.1076, -0.0132, -0.2208,  0.0138,\n",
            "          0.1461, -0.0840],\n",
            "        [ 0.0192, -0.2210,  0.0104, -0.3068, -0.1265, -0.0157,  0.2056, -0.3116,\n",
            "         -0.3095,  0.0930],\n",
            "        [-0.2545,  0.3137, -0.0549, -0.1411,  0.1660, -0.3074,  0.0799, -0.1536,\n",
            "          0.2077, -0.0392],\n",
            "        [-0.2177, -0.0602, -0.2151, -0.2199, -0.0945,  0.1697,  0.1521, -0.2824,\n",
            "         -0.3139, -0.2810],\n",
            "        [ 0.2735, -0.0366, -0.1342, -0.0259, -0.2480, -0.0153, -0.1121,  0.2064,\n",
            "         -0.3039, -0.2993]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.2515, -0.2215, -0.1843,  0.0513,  0.1978], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrzx7Hcg3cdu",
        "outputId": "93464447-3d9b-457e-d98c-68642ed7d6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "class net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5)\n",
        "        self.net  = net2()                                # Parameters of net2 will show up in list of parameters of net3\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net3()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.1676, -0.1372,  0.0040, -0.2970,  0.0183, -0.1208,  0.0138, -0.0338,\n",
            "          0.0225,  0.2892],\n",
            "        [ 0.0530, -0.1297,  0.3044,  0.2584, -0.1964,  0.1988, -0.2823, -0.2115,\n",
            "          0.0275, -0.1710],\n",
            "        [ 0.2897, -0.2155, -0.1130,  0.1452,  0.1035,  0.2507,  0.1279, -0.1951,\n",
            "          0.3065,  0.3117],\n",
            "        [-0.1658,  0.0953, -0.2401,  0.0581, -0.3098, -0.0293,  0.2433, -0.3107,\n",
            "         -0.1754,  0.0978],\n",
            "        [-0.1037,  0.2882,  0.0818,  0.1574,  0.1109, -0.2013,  0.1661,  0.1222,\n",
            "         -0.1524,  0.1598]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.0356, -0.1120,  0.3063, -0.2111,  0.1494], requires_grad=True), Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.2818, -0.0326, -0.1087,  0.1823,  0.1144,  0.2232,  0.1236,  0.0478,\n",
            "         -0.2956,  0.2874],\n",
            "        [ 0.2760, -0.0467,  0.1888, -0.1975,  0.0117, -0.1852,  0.2268,  0.1984,\n",
            "         -0.3136,  0.0341],\n",
            "        [ 0.3058,  0.0297, -0.1345, -0.0605, -0.2798, -0.1163,  0.0456,  0.1661,\n",
            "          0.0768,  0.1556],\n",
            "        [ 0.1662, -0.0734, -0.1512, -0.2200,  0.2390, -0.2995, -0.0766,  0.2787,\n",
            "         -0.0210,  0.1098],\n",
            "        [-0.0825, -0.1492,  0.1884,  0.0663, -0.0139, -0.2194, -0.3115,  0.2319,\n",
            "         -0.2847,  0.0422]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.2680,  0.2211, -0.0064, -0.0752, -0.0117], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3HHO0AT3JSp"
      },
      "source": [
        "## nn.ModuleList和nn.ParameterList（）  \n",
        "<font face=楷体>\n",
        "之前通过PyTorch实现YOLO v3时就用到了nn.ModuleList，通过解析包含该体系结构的文本文件来创建网络，存储Python列表中对应的所有nn.Module对象，使列表成为nn.Module对象的成员代表网络\n",
        "</font>  \n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接**</font>  \n",
        "\n",
        "[【1】PyTorch 中的 ModuleList 和 Sequential: 区别和使用场景](https://zhuanlan.zhihu.com/p/64990232)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkcD_aJqDc3k",
        "outputId": "931e0247-cc74-43ab-d29d-40aa88cb8496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "layer_list = [nn.Conv2d(5,5,3), nn.BatchNorm2d(5), nn.Linear(5,2)]\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = layer_list\n",
        "\n",
        "    def forward(x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "print(list(net.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4AF_ZY5PLa"
      },
      "source": [
        "<font face=楷体>\n",
        "与单个模块不同，Python列表没有被分配到模块的参数列表中。  \n",
        "    \n",
        "为了解决这个问题，我们将列表与nn.ModuleList类封装。然后将其指定为网络类的成员\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtMQ9IqDDc06",
        "outputId": "97593ceb-e93a-4ee8-d71d-8269da63a8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "layer_list = [nn.Conv2d(5,5,3), nn.BatchNorm2d(5), nn.Linear(5,2)]\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layer_list)\n",
        "\n",
        "    def forward(x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "print(list(net.parameters()))  # Parameters of modules in layer_list show up."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[[[ 0.0113,  0.1198,  0.0024],\n",
            "          [ 0.0572,  0.1451, -0.0942],\n",
            "          [-0.0553,  0.1140,  0.1462]],\n",
            "\n",
            "         [[ 0.0610,  0.0324,  0.0173],\n",
            "          [-0.0259, -0.0282, -0.0647],\n",
            "          [ 0.1265,  0.0826,  0.0194]],\n",
            "\n",
            "         [[ 0.0604, -0.0954, -0.0928],\n",
            "          [-0.0149, -0.1048,  0.0245],\n",
            "          [-0.0317,  0.0888, -0.0733]],\n",
            "\n",
            "         [[ 0.0068, -0.0902, -0.1327],\n",
            "          [ 0.0928, -0.0102, -0.1209],\n",
            "          [ 0.1397, -0.0674, -0.0500]],\n",
            "\n",
            "         [[ 0.0261,  0.1271,  0.0450],\n",
            "          [-0.0407, -0.1073, -0.1266],\n",
            "          [ 0.0316, -0.0594, -0.0595]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1372, -0.1372, -0.0668],\n",
            "          [ 0.0413, -0.0246, -0.0841],\n",
            "          [ 0.0691, -0.0539, -0.1472]],\n",
            "\n",
            "         [[-0.1173,  0.1250,  0.0362],\n",
            "          [-0.1179, -0.0109,  0.0123],\n",
            "          [-0.0810, -0.1143,  0.1064]],\n",
            "\n",
            "         [[ 0.0309,  0.1110,  0.1147],\n",
            "          [ 0.0796, -0.0666,  0.1168],\n",
            "          [-0.0121,  0.0219, -0.0840]],\n",
            "\n",
            "         [[ 0.0098, -0.0836, -0.0766],\n",
            "          [-0.0800,  0.1309, -0.1457],\n",
            "          [ 0.0132, -0.1367,  0.0234]],\n",
            "\n",
            "         [[-0.0723,  0.1265, -0.0277],\n",
            "          [-0.0734, -0.1445,  0.0909],\n",
            "          [-0.0062,  0.0893, -0.0205]]],\n",
            "\n",
            "\n",
            "        [[[-0.0630,  0.0691,  0.0049],\n",
            "          [-0.0622, -0.0495,  0.0065],\n",
            "          [-0.0414, -0.1006,  0.1439]],\n",
            "\n",
            "         [[-0.1348, -0.1129,  0.0545],\n",
            "          [-0.0899, -0.0477, -0.0956],\n",
            "          [ 0.0546, -0.0781, -0.1060]],\n",
            "\n",
            "         [[ 0.0309, -0.1223, -0.0810],\n",
            "          [-0.0612, -0.0864,  0.0300],\n",
            "          [ 0.1406, -0.0989, -0.0263]],\n",
            "\n",
            "         [[ 0.1183,  0.1111, -0.0957],\n",
            "          [ 0.0101,  0.1156, -0.0309],\n",
            "          [ 0.1411,  0.0314, -0.0230]],\n",
            "\n",
            "         [[-0.0845,  0.0844, -0.1043],\n",
            "          [-0.0036, -0.0709,  0.0447],\n",
            "          [ 0.0224,  0.0639, -0.1442]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0177, -0.1322,  0.0637],\n",
            "          [-0.0160,  0.1005,  0.0963],\n",
            "          [ 0.0287,  0.1373, -0.0559]],\n",
            "\n",
            "         [[ 0.0607,  0.1137, -0.1044],\n",
            "          [ 0.0887, -0.0018, -0.1226],\n",
            "          [ 0.0923, -0.0778, -0.0794]],\n",
            "\n",
            "         [[ 0.0268,  0.0717, -0.1109],\n",
            "          [ 0.0695,  0.0751,  0.0136],\n",
            "          [-0.0026,  0.0278, -0.0898]],\n",
            "\n",
            "         [[ 0.1201, -0.0942, -0.0234],\n",
            "          [-0.0909,  0.0633, -0.0442],\n",
            "          [-0.0266, -0.0197,  0.0801]],\n",
            "\n",
            "         [[ 0.0272,  0.0163,  0.1164],\n",
            "          [-0.0368, -0.0243, -0.0986],\n",
            "          [-0.0054, -0.1263, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0515, -0.0753,  0.0962],\n",
            "          [-0.1435, -0.0981, -0.0780],\n",
            "          [ 0.0791,  0.0559,  0.0530]],\n",
            "\n",
            "         [[-0.0509, -0.0902, -0.0015],\n",
            "          [ 0.0135,  0.0218,  0.0118],\n",
            "          [-0.0221,  0.0148,  0.0891]],\n",
            "\n",
            "         [[ 0.0295, -0.1378, -0.1436],\n",
            "          [ 0.1213,  0.0219, -0.0411],\n",
            "          [ 0.0825, -0.1229, -0.0357]],\n",
            "\n",
            "         [[-0.0718, -0.1449, -0.0220],\n",
            "          [ 0.0993, -0.0347, -0.0945],\n",
            "          [-0.0670,  0.0961, -0.1435]],\n",
            "\n",
            "         [[ 0.0468, -0.1453,  0.0832],\n",
            "          [-0.0841,  0.0699, -0.0444],\n",
            "          [-0.0249, -0.0335, -0.1023]]]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0856, -0.1449,  0.0608,  0.0752,  0.0700], requires_grad=True), Parameter containing:\n",
            "tensor([0.0354, 0.1126, 0.2441, 0.3270, 0.5581], requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.2553,  0.1247, -0.0574, -0.3664, -0.3168],\n",
            "        [ 0.4063,  0.1691, -0.4437,  0.0899,  0.1705]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4033,  0.2050], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnltjumt6-LY"
      },
      "source": [
        "## 初始化权重\n",
        "<font face=楷体><font face=楷体 color=skyblue  size=4>\n",
        "初始化重量可以影响训练结果，而且对于不同类型的层，可能需要不同的权重初始化方案，通过modules和apply函数来实现：</font>\n",
        "\n",
        "\n",
        "*   modules是nn.Module类的成员函数，它返回一个包含函数的所有成员nn.Module成员对象的迭代器\n",
        "*   可以在每个nn.Module上调用apply函数来设置初始化  \n",
        "    \n",
        "</font>\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gM-wt2BDcyy",
        "outputId": "dd4ff7a0-8afc-4432-b469-7dc12138895c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(10,10,3)\n",
        "        self.bn = nn.BatchNorm2d(10)\n",
        "\n",
        "    def weights_init(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.normal_(module.weight, mean = 0, std = 1)  # torch..nn.init模块中可以找到大量初始化函数\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "\n",
        "Net = myNet()\n",
        "Net.weights_init()\n",
        "\n",
        "for module in Net.modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        weights = module.weight\n",
        "        weights = weights.reshape(-1).detach().cpu().numpy()\n",
        "        print(module.bias)                                       # Bias to zero\n",
        "        plt.hist(weights)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zhlW-0QNjXW"
      },
      "source": [
        "## modules() <font face=STCAIYUN color=yellow  size=5>vs</font> children()  \n",
        "\n",
        "<font face=楷体><font face=楷体 color=skyblue  size=4>\n",
        "和modules非常类似的函数是children，差异很小但很重要：\n",
        "</font>\n",
        "\n",
        "*   nn.Module对象可以包含其他nn.Module对象作为其数据成员\n",
        "*   children()只返回一个调用了children()的nn.Module对象的数据成员列表\n",
        "\n",
        "\n",
        "*   nn.Modulesnn.Modules在每个nn.Module对象内递归，沿着nn.Module创建包含每个对象的列表，返回所有元素（包括不同级别的子元素）\n",
        "\n",
        "<font face=楷体 color=yellow  size=4>注意：</font>modules()还返回nn.Module它作为列表的一部分被调用的内容。   \n",
        "\n",
        "<font face=楷体 color=skyblue>因此，当我们初始化权重时，可能要使用modules()函数，因为我们无法进入nn.Sequential对象并初始化其成员的权重\n",
        "</font>\n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/05/children_vs_modules_pytorch-2.png)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH9bfN_DDcwL",
        "outputId": "e62e3971-c8b1-492a-84da-32fdee114745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convBN =  nn.Sequential(nn.Conv2d(10,10,3), nn.BatchNorm2d(10))\n",
        "        self.linear =  nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "Net = myNet()\n",
        "\n",
        "print(\"Printing children\\n------------------------------\")\n",
        "print(list(Net.children()))\n",
        "print(\"\\n\\nPrinting Modules\\n------------------------------\")\n",
        "print(list(Net.modules()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing children\n",
            "------------------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "), Linear(in_features=10, out_features=2, bias=True)]\n",
            "\n",
            "\n",
            "Printing Modules\n",
            "------------------------------\n",
            "[myNet(\n",
            "  (convBN): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
            "), Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "), Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Linear(in_features=10, out_features=2, bias=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFfuUdo-QYee"
      },
      "source": [
        "## 打印有关网络的信息\n",
        "\n",
        "<font face=楷体><font face=楷体 color=skyblue  size=4>\n",
        "PyTorch提供了一种非常简洁的方法，可以使用它的named_*功能打印有关网络的大量信息，有以下四个方法：\n",
        "</font>\n",
        "\n",
        "*   named_parameters ：返回一个迭代器，给出一个包含参数名称的元组（如果卷积层被指定为self.conv1，那么它的参数将是conv1.weight和conv1.bias）以及由nn.Parameter下的__ repr__函数返回的值\n",
        "\n",
        "*   named_modules ： 与上面相同，但迭代器返回模块（类似modules()的返回）\n",
        "*   与上面相同，但迭代器返回模块（类似children()的返回）\n",
        "\n",
        "\n",
        "*   named_buffers ： 返回缓冲区张量，例如Bn层的移动平均值\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jb_i666Dcts",
        "outputId": "7ac3daa7-3d1c-491e-89de-8ae064d741fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "for x in Net.named_modules():\n",
        "    print(x[0], x[1], \"\\n-------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " myNet(\n",
            "  (convBN): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
            ") \n",
            "-------------------------------\n",
            "convBN Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ") \n",
            "-------------------------------\n",
            "convBN.0 Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)) \n",
            "-------------------------------\n",
            "convBN.1 BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
            "-------------------------------\n",
            "linear Linear(in_features=10, out_features=2, bias=True) \n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgrC-dU3S6vn"
      },
      "source": [
        "## 设置不同层学习率  \n",
        "\n",
        "<font face=楷体>\n",
        "介绍如何针对不同的参数组设置不同的超参数，无论是不同层学习率，或者偏差和权重的学习率。\n",
        "\n",
        "前面实现了CIFAR分类器，将网络所有参数作为一个整体传递给了优化器对象\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuAQW289Dcq9"
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10,5)\n",
        "        self.fc2 = nn.Linear(5,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.fc1(x))\n",
        "\n",
        "Net = myNet()\n",
        "optimiser = torch.optim.SGD(Net.parameters(), lr = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bCGXTpNVH_Z"
      },
      "source": [
        "<font face=楷体>\n",
        "然而，torch.optim类允许以字典形式的参来设置不同学习率\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37cDe3f9Dcnu"
      },
      "source": [
        "optimiser = torch.optim.SGD([{\"params\": Net.fc1.parameters(), 'lr' : 0.001, \"momentum\" : 0.99},\n",
        "                             {\"params\": Net.fc2.parameters()}], lr = 0.01, momentum = 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkgtvdQ0JaVj"
      },
      "source": [
        "params_bias = []\n",
        "params_wts = []\n",
        "\n",
        "# seperate the bias and weights parameters\n",
        "for name, parameter in Net.named_parameters():\n",
        "    if \"bias\" in name:\n",
        "        params_bias.append(parameter)\n",
        "    elif \"weight\" in name:\n",
        "        params_wts.append(parameter)\n",
        "\n",
        "# Set the optimiser to have different hyperparameters for bias and weights\n",
        "optimiser = torch.optim.SGD([{\"params\": params_bias, 'lr' : 0.001, \"momentum\" : 0.99},\n",
        "                             {\"params\": params_wts}], lr = 0.01, momentum = 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHw4PcliGx0s"
      },
      "source": [
        "### 学习率安排  \n",
        "<font face=楷体>\n",
        "torch.optim.lr_scheduler模块提供对学习速率的安排\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1fKalLKujwY"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimiser, milestones = [10,20], gamma = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNF1nFObHggL"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>\n",
        "    训练进行到milestones列表中包含的epoch范围时（$10\\leq epoch<20$），$Learning\\_rate*=gamma$  \n",
        "    </font>\n",
        "\n",
        "<font face=楷体 color=yellow size=4>注意：</font>\n",
        "    <font face=楷体  >\n",
        "\n",
        "*   训练循环一般由两个嵌套循环组成，确保scheduler.step在\"epoch\"循环开始时调用，而不要在\"batch\"循环中调用  \n",
        "*   scheduler.step不能替代optim.step，每次反向传播时都要调用optim.step(在“batch”循环中)\n",
        "</font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC0IOsWALphJ"
      },
      "source": [
        "## 保存模型  \n",
        "<font face=楷体 color=skyblue size=4>PyTorch保存模型有两种选择： </font>\n",
        "<font face=楷体>\n",
        "\n",
        "*   torch.save：保存整个模型用torch.save(the_model, PATH)，相当于nn.Module的Pickle，保存后可用torch.load从内存中加载模型\n",
        "*   state_dict：如果只保存模型中的参数用torch.save(model.state_dict(), PATH)，加载模型时需要自己导入模型的结构信息\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62-y7VwZ9E34",
        "outputId": "b06a4fe7-89f3-4275-fdac-11a8064d8f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "torch.save(Net, \"net.pth\")\n",
        "Net = torch.load(\"net.pth\")\n",
        "print(Net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "myNet(\n",
            "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
            "  (fc2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type myNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNjXVJ5ZLotL",
        "outputId": "1e85e901-6c0b-4940-eeda-ebb474c70980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "for key in Net.state_dict():\n",
        "    print(key, Net.state_dict()[key])\n",
        "\n",
        "torch.save(Net.state_dict(), \"net_state_dict.pth\")\n",
        "Net.load_state_dict(torch.load(\"net_state_dict.pth\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.weight tensor([[-0.0142, -0.1490,  0.2568, -0.2621, -0.0803,  0.0824,  0.1999,  0.2888,\n",
            "          0.0114, -0.0053],\n",
            "        [-0.0471,  0.1405, -0.1094, -0.0921,  0.2265,  0.0744,  0.1465, -0.1262,\n",
            "         -0.1090, -0.2974],\n",
            "        [ 0.0035, -0.0351, -0.1386, -0.2429, -0.1477, -0.1273, -0.0503,  0.0053,\n",
            "          0.2148,  0.2893],\n",
            "        [-0.0885,  0.2263,  0.2858, -0.0348,  0.2520, -0.2159, -0.0207,  0.2793,\n",
            "         -0.2704, -0.1167],\n",
            "        [ 0.1640, -0.0631, -0.3121,  0.1830,  0.2677,  0.2574, -0.2797, -0.0270,\n",
            "          0.1276, -0.0990]])\n",
            "fc1.bias tensor([-0.2203, -0.2941,  0.2389,  0.1853, -0.2126])\n",
            "fc2.weight tensor([[-0.2143,  0.0816, -0.1487, -0.4326, -0.3264],\n",
            "        [-0.1830,  0.2608, -0.1976, -0.1337,  0.3195]])\n",
            "fc2.bias tensor([0.3887, 0.4306])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSxvTv667kkb"
      },
      "source": [
        "#Part- 4 内存管理和多GPU  \n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>1. </font>  <font face=楷体>  多GPU训练网络、数据并行、模型并行     \n",
        "<font face=STCAIYUN color=skyblue size=4>2.</font>   如何在创建新对象时自动选择GPU  \n",
        "<font face=STCAIYUN color=skyblue size=4>3.  </font> 如何诊断和分析内存问题\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjmsGXdjBloy"
      },
      "source": [
        "## 在CPU / GPU上移动Tensor  \n",
        "\n",
        "<font face=楷体><font face=楷体 color=skyblue>PyTorch中每个Tensor都有一个to()成员函数，其所作用是将Tensor放到某个设备上（CPU、GPU$\\cdots$），to()的输入是detorch.device   </font>\n",
        "    \n",
        "<font face=楷体 color=skyblue>torch.cuda.is_available函数</font>检查GPU是否可用\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGwmbSsjLoqc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\tdev = \"cuda:0\"\n",
        "else:\n",
        "\tdev = \"cpu\"\n",
        "\n",
        "device = torch.device(dev)\n",
        "\n",
        "a = torch.zeros(4,3)\n",
        "a = a.to(device)       #alternatively, a.to(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqxWmhLIEqw9"
      },
      "source": [
        "<font face=楷体><font face=楷体 color=skyblue>cuda()函数： </font>将张量放在GPU上的另一种方法是调用cuda(n)，n是GPU的索引\n",
        "    </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Y03RO1G9_M",
        "outputId": "576f720c-b7f4-4b0e-bbc6-1bcb238c41bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "class myNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(5,1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "clf = myNetwork()\n",
        "clf.to(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "myNetwork(\n",
              "  (net): Linear(in_features=5, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKKaP7t-HUvP"
      },
      "source": [
        "## 自动选择GPU  \n",
        "<font face=楷体>PyTorch提供了一些函数实现自动选择GPU ，以减少代码跨设备传输  \n",
        "<font face=楷体 color=skyblue>torch.get_device仅支持GPU张量，返回张量所在的GPU的索引</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjEEGDB6Lonu"
      },
      "source": [
        "dev = a.get_device()\n",
        "b = torch.tensor(a.shape).to(dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHPvK9GfIOWI"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>可以设置创建GPU张量的默认设备</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxb3kXCALolG",
        "outputId": "74a72c3a-2a27-4176-80a0-9c7acb693715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cuda.set_device(0)\n",
        "\n",
        "tens = torch.Tensor(3,4).cuda()\n",
        "tens.get_device()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFdHMWIIyhx"
      },
      "source": [
        "### new_ *函数  \n",
        "\n",
        "<font face=楷体>\n",
        "new_函数成为PyTorch 1.0版的一部分。  \n",
        "    \n",
        "<font face=楷体><font face=楷体 color=skyblue >new_ones函数：</font>返回一个相同数据类型的新张量，并且在与调用new_ones函数的张量相同的设备上"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwl_A4UuLoi5",
        "outputId": "91c32e9a-35b3-4123-94d8-72d91cc5c306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "ones = torch.ones((2,)).cuda(0)\n",
        "\n",
        "# Create a tensor of ones of size (3,4) on same device as of \"ones\"\n",
        "newOnes = ones.new_ones((3,4))\n",
        "\n",
        "randTensor = torch.randn(2,4)\n",
        "print(ones)\n",
        "print(newOnes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1.], device='cuda:0')\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgd4cjtSKJr6"
      },
      "source": [
        "## 多GPU\n",
        "<font face=楷体>\n",
        "<font face=楷体 color=skyblue size=4>两种方式要使用多个GPU：</font>\n",
        "    \n",
        "\n",
        "*   数据并行，将批次分成小批次，并在多个GPU上并行处理这些小批次。\n",
        "*   模型并行，我们将神经网络分解为更小的子网络，在不同的GPU上执行这些子网络。\n",
        " </font>  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t44SQs8BK1xs"
      },
      "source": [
        "### 数据并行\n",
        "<font face=楷体 color=skyblue size=4>通过nn.DataParallel类实现  </font>  \n",
        "<font face=楷体>\n",
        "<font face=楷体 color=skyblue>下图描述了nn.DataParallel如何工作：</font>DataParallel 获取输入，将其分成较小的批次，在所有设备上复制神经网络，执行传递，然后在原始GPU上收集输出  \n",
        "     <font face=楷体 color=yellow size=4 >\n",
        "        注意：\n",
        "    </font>\n",
        "    DataParallel可能在一个GPU（主节点）上施加不对称负载  \n",
        "      <font face=楷体 color=green size=4 >\n",
        "        解决方法：\n",
        "    </font>   \n",
        "    \n",
        "\n",
        "*  向前传播期间计算Loss，确保损失计算阶段是并行的\n",
        "*  实现一个并行的损失函数层\n",
        "\n",
        "\n",
        "         \n",
        "     \n",
        "    \n",
        "    \n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/04/image-4.png)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-X1PM9_Log3"
      },
      "source": [
        "parallel_net = nn.DataParallel(myNet, gpu_ids = [0,1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA3Rll_lQSZE"
      },
      "source": [
        "<font face=楷体 color=skyblue >现在，可以像nn.Module一样简单地执行nn.DataParallel\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu-8hZwrLoc6"
      },
      "source": [
        "predictions = parallel_net(inputs)            # Forward pass on multi-GPUs\n",
        "loss = loss_function(predictions, labels)     # Compute loss function\n",
        "loss.mean().backward()                        # Average GPU-losses + backward pass\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Wtypj0RCUS"
      },
      "source": [
        "<font face=楷体>\n",
        "    <font face=楷体 color=yellow size=4 >\n",
        "        注意：\n",
        "    </font>  \n",
        "    \n",
        "\n",
        "*   尽管数据在多个GPU上并行化，但必须先将其存储在单个GPU上\n",
        "*   确保DataParallel对象也在特定的GPU上\n",
        "      </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX8SQNasLoXK"
      },
      "source": [
        "input        = input.to(0)\n",
        "parallel_net = parellel_net.to(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJcd_Te5UtQj"
      },
      "source": [
        "### 模型并行  \n",
        "\n",
        " <font face=楷体 color=skyblue size=4>网络太大而无法容纳在单个GPU中时 ，可将网络分成较小的子网，然后将其放在不同的GPU上</font>\n",
        "  \n",
        "<font face=楷体 color=yellow size=4 >\n",
        "    注意：\n",
        "</font>\n",
        "    <font face=楷体>\n",
        "    模型并行性通常比数据并行性要慢，因为将单个网络拆分为多个GPU会在GPU之间引入依赖关系，这会阻止它们以真正的并行方式运行  \n",
        "\n",
        "<font face=楷体 color=skyblue>如图：</font>子网2在正向传递期间等待子网1，而子网1在向后传递期间等待子网2  \n",
        "    \n",
        " ![替代文字](https://blog.paperspace.com/content/images/2019/04/model_parallel_steps-1.png)\n",
        "    \n",
        " </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE8aHyi_WKSZ"
      },
      "source": [
        "<font face=楷体><font face=楷体 color=skyblue size=4>\n",
        "    PyTorch实现模型并行要记住两点：\n",
        "</font>\n",
        "\n",
        "*   输入和网络应始终位于同一设备上\n",
        "*   to和cuda函数都支持autograd，反向传播期间可以将gradients从一个GPU复制到另一个GPU\n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtXUx4NdRz3n"
      },
      "source": [
        "class model_parallel(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.sub_network1 = ...\n",
        "\t\tself.sub_network2 = ...\n",
        "\n",
        "\t\tself.sub_network1.cuda(0)\n",
        "\t\tself.sub_network2.cuda(1)\n",
        "\n",
        "\tdef forward(x):\n",
        "\t\tx = x.cuda(0)\n",
        "\t\tx = self.sub_network1(x)\n",
        "\t\tx = x.cuda(1)\n",
        "\t\tx = self.sub_network2(x)\n",
        "\t\treturn x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqVyHjesXtuw"
      },
      "source": [
        "<font face=楷体 color=skyblue>init函数将子网分别放在GPU 0和GPU 1上，在forward函数中，将中间输出从sub_network1传输到GPU 1，然后再将它传输到sub_network2</font>    \n",
        "<font face=楷体 color=yellow size=4 >\n",
        "注意：\n",
        "    </font>\n",
        "    <font face=楷体 >\n",
        "    由于cuda支持autograd，sub_network2反向传播的损失将被复制到sub_network1的缓冲区，以便进一步反向传播\n",
        "    </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgkMpc91aEbM"
      },
      "source": [
        "## 内存管理\n",
        "\n",
        "### 解决内存不足问题\n",
        "\n",
        "<font face=楷体 ><font face=楷体 color=skyblue size=4>\n",
        "如果网络使用的内存超出了所需的内存，如何诊断内存问题和及发现可能的解决方案?  </font>\n",
        "    \n",
        "内存不足可能需要减少批量大小，但可以进行一定的检查以确保内存处于最佳使用状态\n",
        "    \n",
        " </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFtOvZQ1bZuy"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>使用GPUtil跟踪内存使用情况</font>  \n",
        "<font face=楷体 >\n",
        "使用nvidia-smi命令监视控制台中的内存使用情况\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs_8XzkLRz0v",
        "outputId": "d12aa165-7b74-4f53-ca7d-1c7d2667a91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "!pip install GPUtil\n",
        "import GPUtil\n",
        "#!nvidia-smi  # 查看GPU信息\n",
        "GPUtil.showUtilization()  #放在任何想要查看GPU利用率的位置即可"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=77da9469e1a67a6579accc709320a7abff3517639c4c9fd66a0141911a254c48\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  0% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whzvZQrlX8Ba"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>使用del关键字处理内存损失</font>  \n",
        "<font face=楷体>\n",
        "Python不像其他语言（如C / C ++）需要强制声明执行范围，Python变量只有在没有指针的情况下才会被释放。（这也是就是为什么变量无需在Python中声明）  \n",
        "    \n",
        "PyTorch有一个非常有效的垃圾回收机制(gc)。变量一旦超出范围，就会被释放  \n",
        "    \n",
        "<font face=楷体 color=skyblue>因此，如果训练完存储输入和输出tensos占用的内存仍无法释放，可以用del关键字</font>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUrmI4tRzyI",
        "outputId": "f9f1a431-9baf-4224-81d9-7f11ebe8b106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for x in range(10):\n",
        "\ti = x\n",
        "\n",
        "print(i)   # 9 is printed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T63MQ-CR1Xwd"
      },
      "source": [
        "<font face=楷体 color=skyblue>\n",
        "能在循环外打印i，说明变量i没有被释放，那么训练循环迭代也一样，用del关键字释放：\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZaTe1WeRzvX"
      },
      "source": [
        "del out, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UtxbIlCn_QU"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>用Python数据类型代替一维张量</font>  \n",
        "<font face=楷体>\n",
        "用PyTorch每次迭代都会更新损失，一不小心就导致内存占用过多  \n",
        "可以尝试："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zihl7k4jmtgV"
      },
      "source": [
        "total_loss = 0\n",
        "\n",
        "for x in range(10):\n",
        "    # assume loss is computed\n",
        "    iter_loss = torch.randn(3,4).mean()\n",
        "    iter_loss.requires_grad = True     # losses are supposed to differentiable\n",
        "    total_loss += iter_loss            # use total_loss += iter_loss.item) instead"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h37yM5_7RVIF"
      },
      "source": [
        "<font face=楷体 >\n",
        "<font face=楷体 color=skyblue size=4>我们期望在随后的迭代中，对iter_loss的引用被重新分配到新的iter_loss中，并且从早期表示中表示iter_loss的对象将被释放，但这并没有发生，为什么?  </font>\n",
        "\n",
        "由于iter_loss是可微分的，因此total_loss += iter_loss创建了具有一个AddBackward函数节点的计算图。在后续迭代期间，将AddBackward节点添加到此图中，并且不释放iter_loss对象。通常，<font face=楷体 color=yellow>分配给计算图的内存在backward被调用时被释放，但是在这里，没有调用backward  </font>\n",
        "\n",
        "<font face=楷体 color=green size=4>**解决办法：**</font>  \n",
        "\n",
        "将total_loss设置为python数据类型，而不是Tensor，阻止创建任何计算图  \n",
        "<font face=楷体 color=yellow size=4>\n",
        "疑问：  \n",
        "</font>  上下文管理器呢？是否可以用torch.autograd.no_grad?\n",
        "</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/04/loss_add_graph-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjG9z0pUVf96"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>清空Cuda缓存</font>  \n",
        "<font face=楷体 >即使对张量进行了del操作，PyTorch进程也可能不会将内存返回给OS。因为缓存此内存，可以快速将其分配给正在分配的新张量，而不需要向OS请求额外内存  \n",
        "<font face=楷体 color=skyblue>但工作流程中使用两个以上的进程时，这可能是一个问题：  </font>  \n",
        "第一个进程可以保留在GPU内存上，即使它在第二个进程启动时完成了工作也会导致内存不足（OOM）  \n",
        "\n",
        "<font face=楷体 color=green size=4>解决方法：</font>  \n",
        " 可以在代码末尾编写命令：\n",
        "</font>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrXfof0Emtdv"
      },
      "source": [
        "torch.cuda.empy_cache()  # 确保释放进程占用的空间"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfw446NAmtbC",
        "outputId": "61e97085-60a9-4b60-9a40-d313863d1d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "\n",
        "print(\"Initial GPU Usage\")\n",
        "gpu_usage()\n",
        "\n",
        "tensorList = []\n",
        "for x in range(10):\n",
        "    tensorList.append(torch.randn(10000000,10).cuda())   # reduce the size of tensor if you are getting OOM\n",
        "\n",
        "\n",
        "print(\"GPU Usage after allcoating a bunch of Tensors\")\n",
        "gpu_usage()\n",
        "\n",
        "del tensorList\n",
        "\n",
        "print(\"GPU Usage after deleting the Tensors\")\n",
        "gpu_usage()\n",
        "\n",
        "print(\"GPU Usage after emptying the cache\")\n",
        "torch.cuda.empty_cache()\n",
        "gpu_usage()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  3% |\n",
            "GPU Usage after allcoating a bunch of Tensors\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 36% |\n",
            "GPU Usage after deleting the Tensors\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 33% | 36% |\n",
            "GPU Usage after emptying the cache\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 99% |  3% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0UdI9JBbX3o"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>使用torch.no_grad()进行Inference</font>  \n",
        "<font face=楷体>\n",
        "默认情况下，PyTorch将在正向传递期间创建计算图。在创建该图形期间，它将分配缓冲区来存储梯度和中间值，这些值用于在向后传递期间计算梯度  \n",
        "反向传播期间，释放所有这些缓冲区，但leaf variables缓冲区除外  \n",
        "<font color=skyblue>但是，在Inference期间，并不会进行反向传播，这些缓冲区永远不会被释放，从而导致堆积内存</font>   \n",
        "因此，要执行一段不需要反向传播的代码时，将其放在torch.no_grad()上下文管理器中\n",
        "</font>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO3Iel8TmtYS"
      },
      "source": [
        "with torch.no_grad()\n",
        "\t# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liIcUk4Tcfqo"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>使用CuDNN后端</font>  \n",
        "\n",
        "<font face=楷体>\n",
        "CuDNN可以提供很多优化，可以降低你的空间使用量，特别是当神经网络的输入具有固定大小时，在代码顶部添加以下行以启用CuDNN benchmark\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZcof6aMmtVL"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGY78lB7dIYH"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>使用16位浮点数  </font>  \n",
        "<font face=楷体>nVidia的新RTX和Volta支持16位训练和inference.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07cAQnZ0doTr"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>虽然使用16位张量可以将GPU的使用减少近一半，但也存在一些问题：  </font>\n",
        "\n",
        "<font face=楷体>\n",
        "1、批处理规范层具有半精度浮点数收敛问题。如果是这种情况，请确保批量标准层为float32  \n",
        "    \n",
        "2、16位浮点数可能存在溢出问题，确保限制所储存的值\n",
        "    </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni4TVx1RmtSS"
      },
      "source": [
        "model.half()  # convert to half precision\n",
        "for layer in model.modules():\n",
        "    if isinstance(layer, nn.BatchNorm2d):\n",
        "        layer.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDUv0Hakeb4E"
      },
      "source": [
        "<font face=楷体 color=yellow size=4>注意：</font><font face=楷体>确保当输出在forward函数中的不同层间传递时，批量规范图层的输入要从float16转换为float32，然后输出需要转换回float16</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFuzc1Iaf4Cr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KxGMaudf6pO"
      },
      "source": [
        "# Part-5 了解Hooks  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz52F6Tat-pp"
      },
      "source": [
        "PyTorch提供两种类型的钩子：\n",
        "*   The Forward Hook\n",
        "*   The Backward Hook  \n",
        "\n",
        "注意：这些都是torch.Autograd.Function对象的forward和backward被调用时执行\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-wYiLPourjR"
      },
      "source": [
        "## Hooks for Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcXzKMS3f4AT"
      },
      "source": [
        "hook(grad) -> Tensor or None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mZoiWUlf39g",
        "outputId": "bcf1059d-f237-4bc5-a0a8-c2c664e0aad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import torch\n",
        "a = torch.ones(5)\n",
        "a.requires_grad = True\n",
        "\n",
        "b = 2*a\n",
        "\n",
        "b.retain_grad()   # Since b is non-leaf and it's grad will be destroyed otherwise.\n",
        "\n",
        "c = b.mean()\n",
        "\n",
        "c.backward()\n",
        "\n",
        "print(a.grad, b.grad)\n",
        "\n",
        "# Redo the experiment but with a hook that multiplies b's grad by 2.\n",
        "a = torch.ones(5)\n",
        "\n",
        "a.requires_grad = True\n",
        "\n",
        "b = 2*a\n",
        "\n",
        "b.retain_grad()\n",
        "\n",
        "b.register_hook(lambda x: print(x))\n",
        "\n",
        "b.mean().backward()\n",
        "\n",
        "\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n",
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n",
            "tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOEVYIs8f36i"
      },
      "source": [
        "a = torch.ones(5)\n",
        "\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "\n",
        "b.retain_grad()\n",
        "\n",
        "\n",
        "b.mean().backward()\n",
        "\n",
        "\n",
        "print(a.grad, b.grad)\n",
        "\n",
        "b.grad *= 2\n",
        "\n",
        "print(a.grad, b.grad)       # a's gradient needs to updated manually"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWUsDADhvL2I"
      },
      "source": [
        "## Hooks for nn.Module objects  \n",
        "For nn.Module object, the signature for the hook function,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKjNOEYff33m"
      },
      "source": [
        "hook(module, grad_input, grad_output) -> Tensor or None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1TRI0j4vVSf"
      },
      "source": [
        "for the backward hook, and"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELO2AS-6f3z7"
      },
      "source": [
        "hook(module, input, output) -> None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp29yhgef3wz",
        "outputId": "a9974fe7-2ad1-4028-c425-f4aefee49536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1 = nn.Linear(160,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        return self.fc1(self.flatten(x))\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "def hook_fn(m, i, o):\n",
        "    print(m)\n",
        "    print(\"------------Input Grad------------\")\n",
        "\n",
        "    for grad in i:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print (\"None found for Gradient\")\n",
        "\n",
        "    print(\"------------Output Grad------------\")\n",
        "    for grad in o:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print (\"None found for Gradient\")\n",
        "    print(\"\\n\")\n",
        "net.conv.register_backward_hook(hook_fn)\n",
        "net.fc1.register_backward_hook(hook_fn)\n",
        "inp = torch.randn(1,3,8,8)\n",
        "out = net(inp)\n",
        "\n",
        "(1 - out.mean()).backward()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=160, out_features=5, bias=True)\n",
            "------------Input Grad------------\n",
            "torch.Size([5])\n",
            "torch.Size([5])\n",
            "------------Output Grad------------\n",
            "torch.Size([5])\n",
            "\n",
            "\n",
            "Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
            "------------Input Grad------------\n",
            "None found for Gradient\n",
            "torch.Size([10, 3, 2, 2])\n",
            "torch.Size([10])\n",
            "------------Output Grad------------\n",
            "torch.Size([1, 10, 4, 4])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osp9ksxjw-G7"
      },
      "source": [
        "## 正确使用钩子的方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_xJGFlEeT0v",
        "outputId": "45ff9bd9-4e0b-4f52-e05c-a3ead93fd35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1 = nn.Linear(160,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        x.register_hook(lambda grad : torch.clamp(grad, min = 0))     #No gradient shall be backpropagated\n",
        "                                                                  #conv outside less than 0\n",
        "        # print whether there is any negative grad\n",
        "        x.register_hook(lambda grad: print(\"Gradients less than zero:\", bool((grad < 0).any())))\n",
        "        return self.fc1(self.flatten(x))\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "    # if the param is from a linear and is a bias\n",
        "    if \"fc\" in name and \"bias\" in name:\n",
        "        param.register_hook(lambda grad: torch.zeros(grad.shape))\n",
        "\n",
        "\n",
        "out = net(torch.randn(1,3,8,8))\n",
        "\n",
        "(1 - out).mean().backward()\n",
        "\n",
        "print(\"The biases are\", net.fc1.bias.grad)     #bias grads are zero"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients less than zero: False\n",
            "The biases are tensor([0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPk3G7tzxn69"
      },
      "source": [
        "## The Forward Hook for Visualising Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sU2rTMeTyJ"
      },
      "source": [
        "visualisation = {}\n",
        "\n",
        "inp = torch.randn(1,3,8,8)\n",
        "\n",
        "def hook_fn(m, i, o):\n",
        "    visualisation[m] = o\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "for name, layer in net._modules.items():\n",
        "    layer.register_forward_hook(hook_fn)\n",
        "\n",
        "out = net(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EEKe_whxsOD",
        "outputId": "e198b830-3617-447c-906c-30d92126c7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1 = nn.Linear(160,5)\n",
        "        self.seq = nn.Sequential(nn.Linear(5,3), nn.Linear(3,2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        x = self.fc1(self.flatten(x))\n",
        "        x = self.seq(x)\n",
        "\n",
        "net = myNet()\n",
        "visualisation = {}\n",
        "\n",
        "def hook_fn(m, i, o):\n",
        "    visualisation[m] = o\n",
        "\n",
        "def get_all_layers(net):\n",
        "    for name, layer in net._modules.items():\n",
        "    #If it is a sequential, don't register a hook on it\n",
        "    # but recursively register hook on all it's module children\n",
        "        if isinstance(layer, nn.Sequential):\n",
        "            get_all_layers(layer)\n",
        "        else:\n",
        "            # it's a non sequential. Register a hook\n",
        "            layer.register_forward_hook(hook_fn)\n",
        "\n",
        "get_all_layers(net)\n",
        "\n",
        "\n",
        "out = net(torch.randn(1,3,8,8))\n",
        "\n",
        "# Just to check whether we got all layers\n",
        "visualisation.keys()      #output includes sequential layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2)), ReLU(), Linear(in_features=160, out_features=5, bias=True), Linear(in_features=5, out_features=3, bias=True), Linear(in_features=3, out_features=2, bias=True)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSmj-kjaxsLX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq51_IYNeTsJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJEsD8xP8-Pf"
      },
      "source": [
        "***\n",
        "# 搭建神经网络\n",
        "用 torch.nn 包搭建神经网络  \n",
        "\n",
        "nn建立在autograd的基础上来进行模型的定义和微分  \n",
        "**一个典型的神经网络的训练过程：**\n",
        "\n",
        "1、定义一个有着可学习的参数（或者权重）的神经网络  \n",
        "2、对着一个输入的数据集进行迭代:  \n",
        "3、用神经网络对输入进行处理  \n",
        "4、计算代价值 (对输出值的修正到底有多少)  \n",
        "5、将梯度传播回神经网络的参数中  \n",
        "6、更新网络中的权重  \n",
        "$\\qquad$通常使用简单的更新规则: weight = weight + learning_rate * gradient  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlOM8vHesGM"
      },
      "source": [
        "##定义一个神经网络\n",
        "定义一个<font color=geen>**forward函数**</font>，backward会自动地生成， 可以在forward函数中使用所有的Tensor中的操作，模型中可学习的参数会由<font color=geen>**net.parameters()**</font>返回。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9niX6Fg8G8O",
        "outputId": "74c6dccb-acce-4632-db8a-07f908d51281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # If the size is a square you can only specify a single number\n",
        "        x = x.view(-1, self.num_flat_features(x))  # ？？？？？？？？？？？？？？？？？\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:] # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "net = Net()\n",
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mxXftBneZbM"
      },
      "source": [
        "## 输入\n",
        "**注意：** torch.nn包只接受小批量样本，而非单个样本。     \n",
        "例如：nn.Conv2d能够接受四维的$TensornSamples \\times nChannels \\times Height \\times Width$批量样本，\n",
        "如果非要用单个样本，使用input.unsqueeze(0)来加一个假维度就可以了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWa0e8119QGg",
        "outputId": "9f98e66a-9a32-4c3e-d641-74fc196e031b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size()) # conv1's .weight\n",
        "\n",
        "input = Variable(torch.randn(1, 1, 32, 32))\n",
        "out = net(input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsfG_ZpFfKEc"
      },
      "source": [
        "## 反向传播"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfWibyTE-PLG"
      },
      "source": [
        "net.zero_grad() # 对所有的参数的梯度缓冲区进行归零\n",
        "out.backward(torch.randn(1, 10)) # 使用随机的梯度进行反向传播"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3QpTC9XfUjZ"
      },
      "source": [
        "##计算loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKmnx-NXfT3Y",
        "outputId": "bd950846-eca9-4c84-d82b-a26840310791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "output = net(input)\n",
        "target = Variable(torch.range(1, 10))  # a dummy target, for example\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(output, target)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(38.5381, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0TPXLgRrdfw"
      },
      "source": [
        "print(loss.grad_fn) # creator貌似被grad_fn代替了\n",
        "print(loss.grad_fn.previous_functions[0][0]) # Linear\n",
        "print(loss.grad_fn.previous_functions[0][0].previous_functions[0][0]) # ReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOAPopdDKPtK"
      },
      "source": [
        "调用loss.backward()，看看 conv1's在进行反馈之后的偏置梯度如何"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W22B8W0rE5x1",
        "outputId": "19923a7c-be9f-4548-afa3-a5135f895e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# 调用loss.backward(), 看看 conv1's在进行反馈之后的偏置梯度如何\n",
        "net.zero_grad() # 归零操作\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "loss.backward()\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0193, -0.0114,  0.0311,  0.0051, -0.0441, -0.0320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8pYaRWLBkO"
      },
      "source": [
        "***\n",
        "## 更新权重\n",
        "\n",
        "最简单的就是**随机梯度下降法(SGD)：**\n",
        "  ~~~\n",
        "weight = weight - learning_rate * gradient\n",
        "  ~~~\n",
        "**简单的python实现：**\n",
        "  ~~~\n",
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)\n",
        "~~~\n",
        "还有许多不同种类的方法：**SGD, Nesterov-SGD, Adam, RMSProp, etc**，这些方法都可以用**torch.optim包**来实现"
      ]
    }
  ]
}